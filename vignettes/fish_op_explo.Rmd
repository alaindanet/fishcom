---
title: "Exploration of fish operation data"
author: "Alain Danet"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Exploration}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.dim = c(7, 4)
)
library(tidyverse)
library(magrittr)
library(cowplot)
library(ggpmisc)
library(sf)
library(rgdal)
library(lubridate)
devtools::load_all()
theme_set(theme_alain())
```

# What is known 

A meeting with Camille Riviere has permit to get a lot of information about the
fishing operation.

## Historic of the fishing

- Before 1995:
  - Each delegation has its own fishing protocol.
  - Favors sp with high fishing hobby interest
  - unfavorable for sp "bad" for fishing hobbies (Anguille & Lamproie)
- 1995 -: Common protocols
- 2007: Fusion of the regional "Conseil Supérieur de la Pêche" units
  - creation of ONEMA
  - Creation of the `partial_by_point` method: 
    - equal to *complete* when 50 to 100 pt
- 2013 -:
  - Fishing operations are externalized
  - when complete, the passage number is know to 1!

## The fishing network

- RHP:
  - op every year
  - be careful of protocol switch
  - 2% of the site switched location
- RCS (2007-):
  - op every two years
  - standardized fishing operation

## The different fishing method 



## Advise (from Camille Rivière)

- Keep *complete* if
  - series end > 2013, keep only first passage 
  - length of fishing varies more than 30%, delete!

- Merge *point_big_mil* and *partial_over_be* if:
  *partial_over_be* op is:
    - 100% of the points on berges
    - followed over the two berges
    - the two rives have been sampled

- Exclude:
  - site near piscicole station  
  - op concerning targeted species
  - if there is stocking (empoissonnement) 
  - 2 following fishing operations:
    - keep the most complete
    - look at the op objective
    - can be IPR+ program
  

# Analysis

## Summary of the analysis

There are around 6 hundreds stations that have been followed for more than 10
times. Those stations have been sampled every year in average. The sampling
methods seems homogeneous in terms of sampled area. The choice of the sampling
method seems to have been decided according to the size of the river because
alternative to *complete* method has been performed in the high width river. The
*other* method should be exclude of the analysis because they are badly
documented, not numerous and present sampled areas that 5 times higher than the
other methods. For the *complete* operations, there are one or two passages. 

Following the analysis, we refined the dataset for the analysis here:
`data-raw/generate_analysis_dataset.R` (See details in it).

## Preambule

```{r data_prep}
data(operation_data)
op <- dplyr::select(operation_data, opcod:year, count)
rm(operation_data)
```

There was `r nb_op <- length(unique(op$opcod)); nb_op` fishing operations from
`r min(op$year)` to `r max(op$year)`. The sampling was distributed over 
`r nb_st <- length(unique(op$station)); nb_st` stations. It represents a average
effort of `r round(nb_op/nb_st, 1)` (# visit/station).

# Sampling

## Distribution of sampling effort

```{r sampling effort, fig.width = 7}
op_sampling <- op %>%
  group_by(opcod, station, year, month) %>%
  summarise(
    nb_ind = sum(count),
    nb_sp  = n()
    )

op_hist <- op_sampling %>%
  group_by(station) %>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) %>%
  mutate(station = fct_inorder(as.factor(station)))

cdf_op <- ggplot(op_hist, aes(x=freq)) + stat_ecdf() +
  labs(x = "Number of sampling by station",
    y = "Frequency",
    title = "Cumulative distribution function") +
  scale_x_continuous(breaks = seq(0, 30, by = 5)) 
hist_op <- ggplot(op_hist, aes(x = freq)) +
  geom_bar() +
  labs(x = "Number of sampling by station",
    y = "Frequency",
    title = "Frequency distribution") +
  scale_x_continuous(breaks = seq(0, 30, by = 5))

plot_grid(cdf_op, hist_op, ncol = 2) 
``` 

Overall, the sampling effort by station is low and unevenly distributed. More
than 50% of the station had been visited one time and only 10% had been visited
more than 10 times. But we have no information about the spatial distribution of
the station. Some of them are surely really close from each other.

## Sampling effort by year 

```{r, fig.dim = c(4, 4)}
op_year <- op_sampling %>% group_by(year) %>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) 

year_op <- ggplot(op_year, aes(y = freq, x = year)) +
  geom_line() +
  geom_point() +
  labs(y = "Number of sampling events",
    x = "Year",
    title = "")
plot_grid(year_op)
```

We see that the sampling effort increase around 1992 from nearly 250 to 1000
sampled stations by year.

## Sampling area

### Where are the station best followed?

```{r, fig.dim = c(4, 4)}
# good station names
good_station <- op_hist %>% 
  dplyr::filter(freq >= 10) %>%
  dplyr::select(station) %>%
  unlist(., use.names = FALSE)

# get their localisation
station <- read_delim("../data-raw/fishing_station_localisation_wsg84.csv",
  delim = ";", locale = locale("fr", decimal_mark = "."),
  col_types = cols(ST_CODECSP = col_character()))
xy_station <- dplyr::select(station, XCOORD, YCOORD)
station <- SpatialPointsDataFrame(coords = xy_station, data = station,
                               proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
station <- st_as_sf(station)
loc_good_station <- dplyr::filter(station, ST_ID %in% good_station)

# France map
region_fr <- raster::shapefile("../data-raw/france_region_shp/regions-20180101.shp")
##Get only metropolitan areas:
region_fr <- st_as_sf(region_fr) #easier to manipulate
region_to_filter <- c("La Réunion", "Martinique", "Guadeloupe", "Mayotte",
  "Guyane", "Corse")
region_fr <- filter(region_fr, !(nom %in% region_to_filter))
region_fr <- region_fr[, c("nom", "geometry")]

plot(st_geometry(region_fr), lwd = 1.5, col = "grey85")
plot(loc_good_station, pch = 20, col = "red", add = T)
```

They are `r length(good_station)` that has 10 or more sampling points. The good
stations are well distributed over France, this is surprising and super nice.
There is may be a deficit in the south east and east.

#### Number of individuals and species by sampling operation 

```{r, fig.width = 7}
good_station_sampling <- op_sampling %>%
  dplyr::filter(station %in% good_station)
filter(good_station_sampling, nb_sp ==0)

hist_good_station <- good_station_sampling %>%
  ungroup() %>%
  mutate(station = fct_inorder(as.factor(station)))

hist_ind <- ggplot(hist_good_station, aes(x = nb_ind)) +
  geom_histogram(bins = 35) +
  labs(x = "Number of individuals by fish operation",
    y = "Frequency",
    title = "Frequency distribution") +
  scale_x_log10()
hist_sp <- ggplot(hist_good_station, aes(x = nb_sp)) +
  geom_histogram(bins = 32) +
  labs(x = "Number of species by fish operation",
    y = "Frequency",
    title = "Frequency distribution")
plot_grid(hist_ind, hist_sp, ncol = 2)
```

#### Regularity of monitoring

```{r, fig.width = 7}
time_sampling <- good_station_sampling %>%
  ungroup() %>%
  unite(year_month, year, month, sep = "-") %>%
  mutate(times = ymd(paste0(year_month, "-01"))) %>%
  dplyr::select(-year_month)

time_sampling %<>%
  group_by(station) %>%
  arrange(times) %>%
  mutate(
    point = seq(1, length(station)),
    sample_sep = c(NA, times[-1] - times[-length(station)])
  )
hist_time_int <- time_sampling %>%
  summarise(mean_sep = mean(sample_sep, na.rm =TRUE))

global_sep <- ggplot(time_sampling, aes(x = sample_sep)) +
  geom_histogram() +
  geom_vline(aes(xintercept=mean(sample_sep, na.rm = TRUE)),
            color="blue", linetype="dashed", size=1) +
  labs(title = "Frequency distribution",
  x = "Number of days between two sampling points") +
scale_x_continuous(breaks = c(0, 300, 600, 1000, 2000))

average_sep <- ggplot(hist_time_int, aes(x = mean_sep)) +
  geom_histogram() +
  geom_vline(aes(xintercept = mean(mean_sep)),
            color="blue", linetype="dashed", size=1) +
  labs(title = "Frequency distribution",
  x = "Average number of days between two sampling points by station") +
scale_x_continuous(breaks = c(0, 300, 600, 1000, 2000))

plot_grid(average_sep, ncol = 1)
```

The fishing operations (FO) resulted in the collect of several
hundreds of fish (`r mean(hist_good_station$nb_ind)` fishes in average) which is
quite impressive. The delay between two fishing operations by station was of
 `r mean(hist_time_int$mean_sep) %>% round` days, iow 1 year which is great! However, the 
FO that have been spaced by less than one month (30 days), have been taken place
the same day! It is normal because I do not have a date resolution thiner than
the month!

```{r}
# Get operation data
data(operation_data)
operation_data %<>% distinct(opcod, .keep_all = TRUE) %>%
  dplyr::select(-species, -station, -count, -year, -month)
st_method <- left_join(good_station_sampling, operation_data, by = c("opcod")) %>%
  ungroup()

```

```{r}
low_fo_int <- filter(time_sampling, sample_sep < 30) %>%
  ungroup() %>%
  arrange(station) %>%
  left_join(., operation_data, by = c("opcod"))
# Those FO took place the same day:
summarise(low_fo_int, mean = mean(sample_sep))

# Sometimes the first FO was not successful:
filter(time_sampling, station ==  140, point %in% c(9, 10)) 
filter(time_sampling, station ==  472, point %in% c(6, 7))

# But sometimes, no: 
filter(time_sampling, station ==  186, point %in% c(4, 5)) 
filter(time_sampling, station ==  244, point %in% c(15, 16))
# Is it because of differences of sampling methods?

# 
qplot(times, data = low_fo_int, fill = method) +
  labs(x = "Time of monthly repeated sampling")

#To generalize...
```

It concerns `r n_l_samp <- nrow(low_fo_int); n_l_samp` stations,
`r round(n_l_samp / length(good_station) * 100)`% of the good stations.

#### Sampling method regularity


We want to see if the good stations had the same sampling methods across time. 

```{r, fig.width = 7}
## Global distribution of the methods and fishing strategies:
p_met <- ggplot(st_method, aes(method, fill = strategy)) + 
  geom_bar() +
  labs(x = "Sampling Methods",
    y = "Frequency",
    title = "") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
p_met

## Distribution of sampling methods/strategies by station
distri_samp <- st_method %>%
  group_by(station) %>%
  summarise(
    method = length(unique(method)),
    strategy = length(unique(strategy))
  )
p_samp <- ggplot(gather(distri_samp, samp, uniq, method, strategy), aes(x = uniq)) +
  geom_bar() +
  labs(x = "# of different methods/strategies by station",
  y = "Frequency") +
  facet_grid(cols = vars(samp))
p_samp
```

Most of the FO has been realized with the "on foot" strategy. It is probable
that boat has been used in case which the river was too deep.
It is more complicated for the methods. We see hopefully that the methods the
most frequently used was "complete". However, when looking at the number of
different methods used for each station, we see that in general, 1 to 3 methods
are used inside a station.

When there are 2 sampling events at the same station, do they belong to methods
different from complete ? If so, can we merge them ? If not, are they separated
by less than one year ? If not, we should delete them I guess.

#### Characteristics of the sampling methods

```{r}
# let see the states of the variables
op_type <- read_csv("../data-raw/fish_op_variables.csv")
knitr::kable(op_type)
```

- What matters the most:
  - sampling permit to have a good idea of community composition
    - adequat sampling  
    - adequat sampling effort

```{r}
p_surf <- ggplot(st_method, aes(x = method, y = surf)) +
  geom_boxplot() +
  scale_y_log10() +
  labs(x = "Sampling methods", y = "Sampled surface (m^2?)")
p_surf
```

The sampled surfaces are in the same order, which is good. It remains the
question to know if each sampling method allow to have a unbiaised estimation of
the abundances of the species.

```{r fig.dim = c(7, 4)}
data(environmental_data)
st_env <- left_join(st_method, environmental_data, by = "opcod")

# Let's see if some sampling point were to large to perform complete:
width_meth <- ggplot(st_env, aes(x = method, y = width)) +
  geom_boxplot() +
  scale_y_log10() +
  labs(x = "Sampling methods", y = "River width")
width_meth
```
```{r, echo = FALSE}
m_other_surf <- mean(filter(st_method, method == "other")$surf) %>% round
m_autres_surf <- mean(filter(st_method, method != "other")$surf) %>% round
```

We see that the sampling was dependant of the width of the river. It was
expected that in case where the river was really wide. So, may be we should keep
all the methods except "other" because "other" method contains op that has
sampled area `r round(m_other_surf / m_autres_surf, 1)` times higher than the other
(`r m_other_surf` vs `r m_autres_surf`). Furthermore, the variability of the
fishing operation output for "other" method seems much lower.


```{r}
# Let see the correlation between methods and the output of the fishing
# operation
fo_out_methods <- ggplot(gather(st_env, var, nb, nb_ind, nb_sp), aes(x = method, y = nb)) +
  geom_boxplot() +
  scale_y_log10() +
  facet_grid(rows = vars(var), scale = "free_y") +
  labs(x = "Sampling methods", y = "Number of items")
fo_out_methods

## Can those variation be explained by the  area ?
fo_out_surf<- ggplot(gather(st_env, var, nb, nb_ind, nb_sp), aes(x = surf, y = nb)) +
  geom_point() +
  scale_y_log10() +
  scale_x_log10() +
  facet_grid(rows = vars(var), scale = "free_y") +
  labs(x = "Sampled area", y = "Number of items")
fo_out_surf
```

They are quite some differences in the number of species and individuals sampled
according to different methods. But those differences could be attributed to
differences in sampled areas.

#### Quantification of the sampling effort

There is several ways to quantify the sampling effort:
- Sampled area over the river width



```{r}
cte <- 100
test <- tibble(
  width = seq(1, 500),
  raw = width * cte,
  log10 = log10(raw)
)
test %<>% gather(method, surf, raw, log10)
th_surf_width <- ggplot(test, aes(y = surf, x = width)) +
  geom_line() +
  #scale_x_log10() +
  facet_grid(vars(method), scales = "free_y") +
  labs(y = "Sampled area", y = "River width",
    title = "Theoretical relationship")
th_surf_width
```

If we assume a constant length of transect (but it does not make a lot of sens
for other than *complete*), we expect a linear relationship between the sampled
surface and the width of the river. At the log scale, we then expect a
saturating relationship. 

```{r}
surf_width <- ggplot(st_method, aes(y = surf, x = width)) +
  geom_point() +
  scale_y_log10() +
  #scale_x_log10() +
  facet_grid(vars(method)) +
  labs(y = "Sampled area", y = "River width")
surf_width
```

We see that the method *complete*, *facies* and *partial_over_to* are showing
this pattern.

```{r}
# Let's try again without the two big sampled areas
# and free scale for each panel
surf_width <- ggplot(filter(st_method, surf < 10000), aes(y = surf, x = width)) +
  geom_point() +
  facet_grid(vars(method), scales = "free_y") +
  labs(y = "Sampled area", y = "River width")
surf_width
```

We see know that only the *complete* and *partial_over_to* displayed a linear
relationship between sampled surface and river width. It means that the other
methods displayed a more or less constant relationship (*partial_over_be* and
*ambiances* and *facies*).

I think about two solutions:
- We rarefy the little river to equal the poor sampling effort of the big river.
- We separate big rivers and little rivers in the analysis.

What is important is that the sampling effort is homogeneous within station,
right ?

```{r}
# Let's compute the coefficient of variation of sampled area for each station
cv_st <- st_method %>%
  group_by(station) %>%
  summarise(
    avg_width = mean(width, na.rm = TRUE), 
    sd_width = sd(width, na.rm = TRUE),
    avg_surf = mean(surf, na.rm = TRUE), 
    sd_surf = sd(surf, na.rm = TRUE)
  )

p_cv_surf_width <- ggplot(cv_st, aes(y = sd_surf / avg_surf * 100, x = sd_width / avg_width * 100)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red") +
  ylim(0, 300) + xlim(0, 300) + 
  labs(y = "CV of the sampled area (%)", x = "CV of the river width (%)")
p_cv_surf_width

p_cv_surf <- ggplot(cv_st, aes(x = sd_surf / avg_surf * 100)) +
  geom_histogram() +
  labs(x = "CV of the sampled area (%)")
p_cv_surf
```

```{r}
## Watch one
st_test <- filter(st_method, station == sample(good_station, 1))
ggplot(st_test, aes(x = surf)) +
  geom_histogram()


formul <- y ~ x
ggplot(st_test, aes(y = surf, x = width)) +
  geom_point() +
  geom_smooth(method = "lm", color="black") +
  stat_poly_eq(aes(label =  paste(..eq.label.., ..adj.rr.label.., sep = "~~~~")),
               formula = formul, parse = TRUE)

```

```{r}
## Theoretical CV
gen_curve <- function (avg, cv, color) {
  stat_function(fun = dnorm, args = list(mean = avg, sd = cv * avg),
    color = color)
}
gen_label <- function (cv, color, ylabel, avg) {
  annotate("text", x = avg, y = ylabel, label = paste("CV = ", cv * 100, "%"), color = color, size = 5)
}
### data_curve
test <- tibble(
  avg = 500,
  cv = c(.25, .5, 1),
  color = c("blue", "orange", "red"),
  ylabel = c(1.5, .85, .5) / avg
)
### Generate curve
test <- mutate(test, curves = pmap(list(avg, cv, color), gen_curve))
### Generate labels
test <- mutate(test, label = pmap(list(cv, color, ylabel, avg), gen_label))
## Plot
th_cv <- ggplot(data.frame(x = c(0, 1000)), aes(x)) +
  test$curves +# list of curve
  test$label
th_cv
```

The theoretical curve shows that, in case of normal distribution, it would be
safe to remove station were the CV is superior to $.25$. However, this measure
does not take in account the shift of river width. Further exploration are
needed.

One idea: if the length of the transect is *constant*. For each station, we
compute the residuals of the relation between sampled area and the width of the
river

# Check variables

```{r}
st_method %>%
  keep(is.numeric) %>% 
  filter(surf < 20000) %>%
  gather() %>% 
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_histogram()
```

```{r, eval = FALSE}
# It seems that some sampled surfaces are really big:
filter(st_method, surf > 5000)
filter(st_method, station == 8609)
filter(st_method, station == 2952)
## It seems that it is some keyboard errors

# It seems that some sampled surfaces are really big:
filter(st_method, width > 300)
st_method %<>% ungroup()
filter(st_method, method != "complete") %>%
  dplyr::select(nbpass) %>%
  unique()
```

